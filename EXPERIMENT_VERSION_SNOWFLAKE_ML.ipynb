{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# User Activity Prediction - Feature Store & Experiment Tracking\n",
    "# =============================================================================\n",
    "# This notebook demonstrates an end-to-end ML workflow using Snowflake's native\n",
    "# ML capabilities: Feature Store, Experiment Tracking, and Model Registry.\n",
    "# =============================================================================\n",
    "\n",
    "# Import python packages\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from snowflake.snowpark.functions import (\n",
    "    col, count, avg, max as max_, min as min_, dateadd, lit, sum as sum_, \n",
    "    coalesce, datediff, any_value, when, iff\n",
    ")\n",
    "from snowflake.ml.feature_store import FeatureStore, Entity, FeatureView, CreationMode\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Get Snowpark session\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "\n",
    "# =============================================================================\n",
    "# Configuration - Centralized parameters for easy management\n",
    "# =============================================================================\n",
    "CONFIG = {\n",
    "    \"database\": \"dev\",\n",
    "    \"feature_store_name\": \"user_activity_feature_store\",\n",
    "    \"warehouse\": \"ds_wh_medium\",\n",
    "    \"feature_refresh_freq\": \"24 hours\",\n",
    "    \"lookback_days\": 7,  # For rolling window features\n",
    "    \"test_size\": 0.2,\n",
    "    \"random_state\": 42\n",
    "}\n",
    "\n",
    "logger.info(f\"Configuration loaded: {CONFIG}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55dea84-77bf-44eb-a70d-a9de85fad360",
   "metadata": {
    "collapsed": false,
    "name": "cell3"
   },
   "source": [
    "## 1. Data Preparation\n",
    "\n",
    "Features are computed at **daily granularity** (`date_utc`) to:\n",
    "- Avoid `CURRENT_DATE()` dependencies (better for reproducibility)\n",
    "- Enable point-in-time correct feature retrieval\n",
    "- Support incremental updates efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d476f-3aeb-4874-92e6-64ff055644ae",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "#### Call quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383f5692-ed59-4fd4-a7dc-c63741424c4d",
   "metadata": {
    "language": "python",
    "name": "cell47"
   },
   "outputs": [],
   "source": [
    "Each feature query includes `date_utc` for daily-level aggregation and uses parameterized lookback windows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc2cdd5-185b-4d2b-89e7-b04915f0e6e2",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "# Call Quality Features - Daily granularity\n",
    "user_features_call_quality_df = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    call_date AS date_utc,\n",
    "    USER_ID_HEX,\n",
    "    \n",
    "    -- All-time cumulative features (up to this date)\n",
    "    CAST(COUNT_IF(COALESCE(num_bad_mos_periods, 0) > 0) AS FLOAT) AS calls_with_bad_mos,\n",
    "    CAST(AVG(computed_mos) AS FLOAT) AS average_mos,\n",
    "    CAST(MAX(RTP_SETUP_TIME) AS FLOAT) AS max_rtp_setup_time,\n",
    "    \n",
    "    -- Rolling 7-day features\n",
    "    CAST(COUNT_IF(\n",
    "        call_date >= DATEADD('day', -{CONFIG['lookback_days']}, call_date) \n",
    "        AND COALESCE(num_bad_mos_periods, 0) > 0\n",
    "    ) AS FLOAT) AS calls_with_bad_mos_7d,\n",
    "    CAST(AVG(CASE \n",
    "        WHEN call_date >= DATEADD('day', -{CONFIG['lookback_days']}, call_date) \n",
    "        THEN computed_mos \n",
    "    END) AS FLOAT) AS average_mos_7d,\n",
    "    CAST(MAX(CASE \n",
    "        WHEN call_date >= DATEADD('day', -{CONFIG['lookback_days']}, call_date) \n",
    "        THEN RTP_SETUP_TIME \n",
    "    END) AS FLOAT) AS max_rtp_setup_time_7d\n",
    "\n",
    "FROM dev.public.legacy_call_end\n",
    "WHERE USER_ID_HEX != '000-00-000-000000000'\n",
    "    AND USER_ID_HEX IS NOT NULL\n",
    "GROUP BY call_date, USER_ID_HEX\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"Call Quality features: {user_features_call_quality_df.count()} rows\")\n",
    "user_features_call_quality_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603cdb18-465d-4929-ba22-6e388e619799",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "#### Call rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell2"
   },
   "outputs": [],
   "source": [
    "# Call Rating Features - Daily granularity\n",
    "user_features_call_rating_df = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    date_utc,\n",
    "    user_id_hex,\n",
    "    \n",
    "    -- All-time cumulative features\n",
    "    CAST(COUNT(call_rating) AS FLOAT) AS call_rating_count,\n",
    "    CAST(AVG(call_rating) AS FLOAT) AS avg_call_rating,\n",
    "    CAST(MAX(call_rating) AS FLOAT) AS max_call_rating,\n",
    "    CAST(MIN(call_rating) AS FLOAT) AS min_call_rating,\n",
    "    \n",
    "    -- Rolling 7-day features\n",
    "    CAST(COUNT(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN call_rating \n",
    "    END) AS FLOAT) AS call_rating_count_7d,\n",
    "    CAST(AVG(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN call_rating \n",
    "    END) AS FLOAT) AS avg_call_rating_7d,\n",
    "    CAST(MAX(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN call_rating \n",
    "    END) AS FLOAT) AS max_call_rating_7d,\n",
    "    CAST(MIN(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN call_rating \n",
    "    END) AS FLOAT) AS min_call_rating_7d\n",
    "\n",
    "FROM dev.public.call_ratings_combined_sources\n",
    "WHERE call_rating > 0\n",
    "    AND user_id_hex != '000-00-000-000000000'\n",
    "    AND user_id_hex IS NOT NULL\n",
    "GROUP BY date_utc, user_id_hex\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"Call Rating features: {user_features_call_rating_df.count()} rows\")\n",
    "user_features_call_rating_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9686b061-7650-4ff3-945b-b8c0c6bd13b2",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "#### Data usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9567f26-69ea-4169-8767-f404b96227f3",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": [
    "# Data Usage Features - Daily granularity\n",
    "user_features_data_usage_df = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    c.date_utc,\n",
    "    up.user_id_hex,\n",
    "    \n",
    "    -- All-time cumulative features\n",
    "    CAST(SUM(c.mb_usage) AS FLOAT) AS data_usage_mb,\n",
    "    \n",
    "    -- Rolling 7-day features\n",
    "    CAST(SUM(CASE \n",
    "        WHEN c.date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, c.date_utc) \n",
    "        THEN c.mb_usage \n",
    "        ELSE 0 \n",
    "    END) AS FLOAT) AS data_usage_mb_7d\n",
    "\n",
    "FROM dev.public.cost_user_daily_tmobile_cost c\n",
    "JOIN dev.public.user_profiles up ON c.username = up.latest_username\n",
    "WHERE up.user_id_hex IS NOT NULL\n",
    "    AND up.user_id_hex != '000-00-000-000000000'\n",
    "GROUP BY c.date_utc, up.user_id_hex\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"Data Usage features: {user_features_data_usage_df.count()} rows\")\n",
    "user_features_data_usage_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb3cf53-b819-4430-981b-5bb2368e6449",
   "metadata": {
    "collapsed": false,
    "name": "cell4"
   },
   "source": [
    "#### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aebd30-27bc-4e89-979e-597dc934e1e0",
   "metadata": {
    "language": "python",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "# Session Features - Daily granularity\n",
    "user_features_sessions_df = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    m.date_utc,\n",
    "    up.user_id_hex,\n",
    "    \n",
    "    -- All-time cumulative features\n",
    "    CAST(SUM(m.time_in_app_mins_per_day) AS FLOAT) AS time_in_app_mins,\n",
    "    CAST(DATEDIFF('day', ANY_VALUE(up.registered_at), m.date_utc) AS FLOAT) AS tenure_days,\n",
    "    CAST(SUM(m.num_sessions) AS FLOAT) AS session_count,\n",
    "    \n",
    "    -- Rolling 7-day features\n",
    "    CAST(SUM(CASE \n",
    "        WHEN m.date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, m.date_utc) \n",
    "        THEN m.time_in_app_mins_per_day \n",
    "        ELSE 0 \n",
    "    END) AS FLOAT) AS time_in_app_mins_7d,\n",
    "    CAST(SUM(CASE \n",
    "        WHEN m.date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, m.date_utc) \n",
    "        THEN m.num_sessions \n",
    "        ELSE 0 \n",
    "    END) AS FLOAT) AS session_count_7d\n",
    "\n",
    "FROM dev.public.metrics_daily_userlevel_app_time_sessions m\n",
    "JOIN dev.public.user_profiles up ON m.username = up.latest_username\n",
    "WHERE up.user_id_hex IS NOT NULL\n",
    "    AND up.user_id_hex != '000-00-000-000000000'\n",
    "GROUP BY m.date_utc, up.user_id_hex\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"Session features: {user_features_sessions_df.count()} rows\")\n",
    "user_features_sessions_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573e6855-47b1-45ce-813b-9039800c2a19",
   "metadata": {
    "collapsed": false,
    "name": "cell12"
   },
   "source": [
    "#### NPS ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245c2997-2d0f-4ea1-90dd-8a3d2b96ffc2",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "# NPS Rating Features - Daily granularity\n",
    "user_features_nps_rating_df = session.sql(f\"\"\"\n",
    "SELECT \n",
    "    date_utc,\n",
    "    user_id_hex,\n",
    "    \n",
    "    -- All-time cumulative features\n",
    "    CAST(COUNT(*) AS FLOAT) AS nps_count,\n",
    "    CAST(AVG(score) AS FLOAT) AS nps_avg_rating,\n",
    "    CAST(MAX(score) AS FLOAT) AS nps_max_rating,\n",
    "    \n",
    "    -- Rolling 7-day features\n",
    "    CAST(COUNT(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN 1 \n",
    "    END) AS FLOAT) AS nps_count_7d,\n",
    "    CAST(AVG(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN score \n",
    "    END) AS FLOAT) AS nps_avg_rating_7d,\n",
    "    CAST(MAX(CASE \n",
    "        WHEN date_utc >= DATEADD('day', -{CONFIG['lookback_days']}, date_utc) \n",
    "        THEN score \n",
    "    END) AS FLOAT) AS nps_max_rating_7d\n",
    "\n",
    "FROM dev.public.nps_combined_sources\n",
    "WHERE user_id_hex != '000-00-000-000000000'\n",
    "    AND user_id_hex IS NOT NULL\n",
    "GROUP BY date_utc, user_id_hex\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"NPS Rating features: {user_features_nps_rating_df.count()} rows\")\n",
    "user_features_nps_rating_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6875e5-b933-4af5-9169-85bc2f38e0a6",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "## 2. Feature Store\n",
    "\n",
    "Snowflake Feature Store provides:\n",
    "- **Centralized feature management** with versioning\n",
    "- **Point-in-time correct** feature retrieval for training\n",
    "- **Automatic refresh** via dynamic tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662eea8d-9482-43f3-bde1-b936d97519fc",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "#### Create FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94842b07-e510-421c-b09e-ca26a3b0313a",
   "metadata": {
    "language": "python",
    "name": "cell32"
   },
   "outputs": [],
   "source": [
    "# fs = FeatureStore(\n",
    "#     session=session,\n",
    "#     database=\"dev\",\n",
    "#     name=\"user_activity_feature_store\",\n",
    "#     default_warehouse=\"ds_wh_medium\",\n",
    "#     creation_mode=CreationMode.CREATE_IF_NOT_EXIST\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048df28-e948-4df3-ab01-3c100efbb755",
   "metadata": {
    "collapsed": false,
    "name": "cell16"
   },
   "source": [
    "#### Connect to FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0f328d-8589-49d1-88f8-68cbcdfc0ff3",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": [
    "# Connect to existing Feature Store\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=CONFIG[\"database\"],\n",
    "    name=CONFIG[\"feature_store_name\"],\n",
    "    default_warehouse=CONFIG[\"warehouse\"]\n",
    ")\n",
    "\n",
    "logger.info(f\"Connected to Feature Store: {CONFIG['feature_store_name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219cd46-8aa1-4387-900f-bd76d6fa9e08",
   "metadata": {
    "collapsed": false,
    "name": "cell33"
   },
   "source": [
    "#### Create and register entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42a7fae-1e8c-406a-ae85-a30e4b651b7d",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "# entity = Entity(\n",
    "#     name=\"user\",\n",
    "#     join_keys=[\"user_id_hex\"],\n",
    "#     desc=\"user entity\"\n",
    "# )\n",
    "# fs.register_entity(entity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5950726e-a5a8-4194-b8b6-f9987b91c5fd",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "#### Get existing entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e164b8b-2a49-4c4c-b7b4-10b9829c4bfb",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "entity = fs.get_entity(\"user\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f338f0d5-dad2-4f9a-9d1b-834ff4bbec75",
   "metadata": {
    "collapsed": false,
    "name": "cell10"
   },
   "source": [
    "#### Create and register feature views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b5aef-1c20-4436-8801-cf626b22704d",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "# Call Quality Feature View\n",
    "user_features_call_quality_fv = FeatureView(\n",
    "    name=\"user_features_call_quality\",\n",
    "    entities=[entity],\n",
    "    feature_df=user_features_call_quality_df,\n",
    "    timestamp_col=\"DATE_UTC\",  # Enable point-in-time lookups\n",
    "    refresh_freq=CONFIG[\"feature_refresh_freq\"],\n",
    "    desc=\"User call quality metrics including MOS scores and bad call counts\"\n",
    ")\n",
    "\n",
    "fs.register_feature_view(\n",
    "    feature_view=user_features_call_quality_fv,\n",
    "    version=\"1\",\n",
    "    overwrite=True  # Allow re-registration during development\n",
    ")\n",
    "logger.info(\"Registered: user_features_call_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6ba8d-04e8-4428-83e5-8d07f6773737",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "# Call Rating Feature View\n",
    "user_features_call_rating_fv = FeatureView(\n",
    "    name=\"user_features_call_rating\",\n",
    "    entities=[entity],\n",
    "    feature_df=user_features_call_rating_df,\n",
    "    timestamp_col=\"DATE_UTC\",\n",
    "    refresh_freq=CONFIG[\"feature_refresh_freq\"],\n",
    "    desc=\"User call rating statistics and trends\"\n",
    ")\n",
    "\n",
    "fs.register_feature_view(\n",
    "    feature_view=user_features_call_rating_fv,\n",
    "    version=\"1\",\n",
    "    overwrite=True\n",
    ")\n",
    "logger.info(\"Registered: user_features_call_rating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e47333-ef0e-4cb1-8a79-52553993ed8f",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "# Data Usage Feature View\n",
    "user_features_data_usage_fv = FeatureView(\n",
    "    name=\"user_features_data_usage\",\n",
    "    entities=[entity],\n",
    "    feature_df=user_features_data_usage_df,\n",
    "    timestamp_col=\"DATE_UTC\",\n",
    "    refresh_freq=CONFIG[\"feature_refresh_freq\"],\n",
    "    desc=\"User mobile data consumption patterns\"\n",
    ")\n",
    "\n",
    "fs.register_feature_view(\n",
    "    feature_view=user_features_data_usage_fv,\n",
    "    version=\"1\",\n",
    "    overwrite=True\n",
    ")\n",
    "logger.info(\"Registered: user_features_data_usage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79305644-899b-48f9-af02-d86f375ad818",
   "metadata": {
    "language": "python",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "# Sessions Feature View\n",
    "user_features_sessions_fv = FeatureView(\n",
    "    name=\"user_features_sessions\",\n",
    "    entities=[entity],\n",
    "    feature_df=user_features_sessions_df,\n",
    "    timestamp_col=\"DATE_UTC\",\n",
    "    refresh_freq=CONFIG[\"feature_refresh_freq\"],\n",
    "    desc=\"User app session and engagement metrics\"\n",
    ")\n",
    "\n",
    "fs.register_feature_view(\n",
    "    feature_view=user_features_sessions_fv,\n",
    "    version=\"1\",\n",
    "    overwrite=True\n",
    ")\n",
    "logger.info(\"Registered: user_features_sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5da96-5362-4786-a64a-9cb8a24cb8af",
   "metadata": {
    "language": "python",
    "name": "cell23"
   },
   "outputs": [],
   "source": [
    "# NPS Rating Feature View\n",
    "user_features_nps_rating_fv = FeatureView(\n",
    "    name=\"user_features_nps_rating\",\n",
    "    entities=[entity],\n",
    "    feature_df=user_features_nps_rating_df,\n",
    "    timestamp_col=\"DATE_UTC\",\n",
    "    refresh_freq=CONFIG[\"feature_refresh_freq\"],\n",
    "    desc=\"User NPS (Net Promoter Score) feedback metrics\"\n",
    ")\n",
    "\n",
    "fs.register_feature_view(\n",
    "    feature_view=user_features_nps_rating_fv,\n",
    "    version=\"1\",\n",
    "    overwrite=True\n",
    ")\n",
    "logger.info(\"Registered: user_features_nps_rating\")\n",
    "\n",
    "# Summary of registered feature views\n",
    "logger.info(\"=\" * 50)\n",
    "logger.info(\"All 5 feature views registered successfully!\")\n",
    "logger.info(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdc3bc5-4251-487b-9278-9e0dc6539671",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "## 3. Model Training\n",
    "\n",
    "Train baseline models with Snowflake Experiment Tracking to:\n",
    "- Compare multiple algorithms\n",
    "- Log metrics, parameters, and model artifacts\n",
    "- Track experiment lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db6d4d-96ea-48fc-b337-f989d101864e",
   "metadata": {
    "language": "python",
    "name": "cell35"
   },
   "outputs": [],
   "source": [
    "# ML Libraries - Using Snowflake ML instead of sklearn\n",
    "from snowflake.ml.modeling.linear_model import LinearRegression, Ridge, Lasso\n",
    "from snowflake.ml.modeling.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml.modeling.lightgbm import LGBMRegressor\n",
    "from snowflake.ml.modeling.preprocessing import StandardScaler\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from snowflake.ml.experiment import ExperimentTracking\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Experiment Tracking\n",
    "EXPERIMENT_NAME = \"user_activity_forecasting_baseline\"\n",
    "\n",
    "exp = ExperimentTracking(session=session)\n",
    "exp.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "logger.info(f\"Experiment initialized: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b737f6-fe67-4a1e-9778-b968077b50a7",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "#### Spine df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ee0b5-9169-4d08-94c5-74ae3032ac24",
   "metadata": {
    "language": "python",
    "name": "cell28"
   },
   "outputs": [],
   "source": [
    "# Define training date range (avoids CURRENT_DATE() for reproducibility)\n",
    "# In production, pass these as parameters\n",
    "TRAINING_END_DATE = \"2024-12-01\"  # Adjust to your data's available date\n",
    "TRAINING_START_DATE = \"2024-11-17\"  # 14 days before end date\n",
    "\n",
    "# Spine DataFrame: Target variable (active_days_in_week)\n",
    "spine_df = session.sql(f\"\"\"\n",
    "SELECT\n",
    "    '{TRAINING_END_DATE}'::DATE AS date_utc,  -- Reference date for feature lookup\n",
    "    up.user_id_hex,\n",
    "    SUM(IFF(m.time_in_app_mins_per_day > 1, 1, 0)) AS active_days_in_week\n",
    "FROM dev.public.metrics_daily_userlevel_app_time_sessions m\n",
    "JOIN dev.public.user_profiles up ON m.username = up.latest_username\n",
    "WHERE m.date_utc BETWEEN '{TRAINING_START_DATE}' AND '{TRAINING_END_DATE}'\n",
    "    AND up.user_id_hex IS NOT NULL\n",
    "    AND up.user_id_hex != '000-00-000-000000000'\n",
    "GROUP BY up.user_id_hex\n",
    "\"\"\")\n",
    "\n",
    "logger.info(f\"Spine DataFrame: {spine_df.count()} users\")\n",
    "logger.info(f\"Training period: {TRAINING_START_DATE} to {TRAINING_END_DATE}\")\n",
    "spine_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21daba-2cba-4ee1-9bcd-9e2f566f9b18",
   "metadata": {
    "collapsed": false,
    "name": "cell30"
   },
   "source": [
    "#### Get training dataset from FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a56c7b-d241-408f-a6d9-855f76a16219",
   "metadata": {
    "language": "python",
    "name": "cell29"
   },
   "outputs": [],
   "source": [
    "# Retrieve ALL feature views (using all 5, not just 2)\n",
    "fv_call_quality = fs.get_feature_view(name=\"user_features_call_quality\", version=\"1\")\n",
    "fv_call_rating = fs.get_feature_view(name=\"user_features_call_rating\", version=\"1\")\n",
    "fv_data_usage = fs.get_feature_view(name=\"user_features_data_usage\", version=\"1\")\n",
    "fv_sessions = fs.get_feature_view(name=\"user_features_sessions\", version=\"1\")\n",
    "fv_nps_rating = fs.get_feature_view(name=\"user_features_nps_rating\", version=\"1\")\n",
    "\n",
    "# Generate training set with point-in-time join\n",
    "all_features = [\n",
    "    fv_call_quality, \n",
    "    fv_call_rating, \n",
    "    fv_data_usage, \n",
    "    fv_sessions, \n",
    "    fv_nps_rating\n",
    "]\n",
    "\n",
    "training_df = fs.generate_training_set(\n",
    "    spine_df=spine_df,\n",
    "    features=all_features,\n",
    "    spine_timestamp_col=\"DATE_UTC\",  # For point-in-time correct joins\n",
    "    spine_label_cols=[\"ACTIVE_DAYS_IN_WEEK\"]\n",
    ")\n",
    "\n",
    "# Keep as Snowpark DataFrame (no .to_pandas() - Snowflake ML works directly with Snowpark DF!)\n",
    "logger.info(f\"Training dataset: {training_df.count()} rows\")\n",
    "logger.info(f\"Features: {training_df.columns}\")\n",
    "training_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53397559-0294-42c5-b841-6415c6b1db0c",
   "metadata": {
    "collapsed": false,
    "name": "cell25"
   },
   "source": [
    "#### Split training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e042cafe-6c83-4e56-9fdd-ad724e72c8e2",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "# Define feature and label columns for Snowflake ML\n",
    "from snowflake.snowpark.types import FloatType, DoubleType, IntegerType, LongType, DecimalType\n",
    "\n",
    "LABEL_COL = \"ACTIVE_DAYS_IN_WEEK\"\n",
    "ID_COLS = [\"USER_ID_HEX\", \"DATE_UTC\"]\n",
    "\n",
    "# Get numerical types for filtering\n",
    "NUMERICAL_TYPES = (FloatType, DoubleType, IntegerType, LongType, DecimalType)\n",
    "\n",
    "# Get ALL feature columns (excluding ID and label)\n",
    "ALL_FEATURE_COLS = [c for c in training_df.columns if c not in ID_COLS + [LABEL_COL]]\n",
    "\n",
    "# Filter to only NUMERICAL columns using schema\n",
    "NUMERICAL_COLS = [\n",
    "    field.name for field in training_df.schema.fields \n",
    "    if field.name in ALL_FEATURE_COLS and isinstance(field.datatype, NUMERICAL_TYPES)\n",
    "]\n",
    "\n",
    "# Use numerical columns for scaling, all features for model\n",
    "FEATURE_COLS = ALL_FEATURE_COLS  # All features for the model\n",
    "SCALE_COLS = NUMERICAL_COLS      # Only numerical for StandardScaler\n",
    "\n",
    "logger.info(f\"Total features: {len(FEATURE_COLS)} columns\")\n",
    "logger.info(f\"Numerical features (for scaling): {len(SCALE_COLS)} columns\")\n",
    "logger.info(f\"Label: {LABEL_COL}\")\n",
    "\n",
    "# Handle nulls in Snowpark DF\n",
    "training_df = training_df.fillna(0)\n",
    "\n",
    "# Split using Snowpark random_split (80-20 train/test ratio)\n",
    "train_df, test_df = training_df.random_split(\n",
    "    weights=[0.8, 0.2], \n",
    "    seed=CONFIG[\"random_state\"]\n",
    ")\n",
    "\n",
    "logger.info(f\"Training set: {train_df.count()} samples\")\n",
    "logger.info(f\"Test set: {test_df.count()} samples\")\n",
    "logger.info(f\"Features used: {len(FEATURE_COLS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107a2d1c-fac9-4cfc-94e3-6144b4952cb4",
   "metadata": {
    "collapsed": false,
    "name": "cell39"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd9237d-9e9a-4aba-8cc3-40b09502b160",
   "metadata": {
    "language": "python",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "# Snowflake ML StandardScaler - only applied to NUMERICAL columns\n",
    "# Non-numerical columns pass through unchanged\n",
    "scaler = StandardScaler(\n",
    "    input_cols=SCALE_COLS,      # Only numerical columns\n",
    "    output_cols=SCALE_COLS      # Overwrite in place\n",
    ")\n",
    "\n",
    "logger.info(f\"Scaler configured for {len(SCALE_COLS)} numerical features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f3a39-cc00-4f47-b589-15d377f55bdf",
   "metadata": {
    "collapsed": false,
    "name": "cell36"
   },
   "source": [
    "#### Base training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ced4e3-0af4-4579-91f6-e6ae1444a291",
   "metadata": {
    "language": "python",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "# Define baseline models with Snowflake ML API\n",
    "# Key difference: Must specify input_cols, label_cols, output_cols\n",
    "baseline_models = [\n",
    "    # Linear models\n",
    "    (\"LinearRegression\", LinearRegression(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"]\n",
    "    )),\n",
    "    (\"Ridge\", Ridge(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"]\n",
    "    )),\n",
    "    (\"Lasso\", Lasso(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"]\n",
    "    )),\n",
    "    \n",
    "    # Tree-based models\n",
    "    (\"RandomForest\", RandomForestRegressor(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"],\n",
    "        n_estimators=100,\n",
    "        random_state=CONFIG[\"random_state\"]\n",
    "    )),\n",
    "    (\"GradientBoosting\", GradientBoostingRegressor(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"],\n",
    "        random_state=CONFIG[\"random_state\"]\n",
    "    )),\n",
    "    \n",
    "    # Boosting models\n",
    "    (\"XGBoost\", XGBRegressor(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"],\n",
    "        random_state=CONFIG[\"random_state\"]\n",
    "    )),\n",
    "    (\"LightGBM\", LGBMRegressor(\n",
    "        input_cols=FEATURE_COLS,\n",
    "        label_cols=[LABEL_COL],\n",
    "        output_cols=[\"PREDICTION\"],\n",
    "        random_state=CONFIG[\"random_state\"]\n",
    "    ))\n",
    "]\n",
    "\n",
    "logger.info(f\"Prepared {len(baseline_models)} baseline models for training (Snowflake ML)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d89592-9c54-4d96-9fd4-604725dcc519",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "cell38"
   },
   "outputs": [],
   "source": [
    "# Training loop with Snowflake ML using Pipeline\n",
    "results = []\n",
    "\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(\"TRAINING BASELINE MODELS (Snowflake ML with Pipeline)\")\n",
    "logger.info(\"=\" * 60)\n",
    "\n",
    "for name, model in baseline_models:\n",
    "    logger.info(f\"\\nTraining: {name}\")\n",
    "    \n",
    "    # Build pipeline with preprocessing (StandardScaler on numerical cols only + Model)\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"scaler\", StandardScaler(input_cols=SCALE_COLS, output_cols=SCALE_COLS)),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    \n",
    "    # Fit pipeline on training data\n",
    "    pipeline.fit(train_df)\n",
    "    \n",
    "    # Predict on test data - returns Snowpark DataFrame with PREDICTION column\n",
    "    predictions_df = pipeline.predict(test_df)\n",
    "    \n",
    "    # Calculate metrics using Snowflake ML metrics API\n",
    "    mse = mean_squared_error(\n",
    "        df=predictions_df, \n",
    "        y_true_col_names=[LABEL_COL], \n",
    "        y_pred_col_names=[\"PREDICTION\"]\n",
    "    )\n",
    "    mae = mean_absolute_error(\n",
    "        df=predictions_df, \n",
    "        y_true_col_names=[LABEL_COL], \n",
    "        y_pred_col_names=[\"PREDICTION\"]\n",
    "    )\n",
    "    r2 = r2_score(\n",
    "        df=predictions_df, \n",
    "        y_true_col_names=[LABEL_COL], \n",
    "        y_pred_col_names=[\"PREDICTION\"]\n",
    "    )\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    results.append({\n",
    "        \"name\": name,\n",
    "        \"mse\": mse,\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"r2\": r2,\n",
    "        \"pipeline\": pipeline\n",
    "    })\n",
    "    \n",
    "    logger.info(f\"  MSE: {mse:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | R¬≤: {r2:.4f}\")\n",
    "    \n",
    "    # Log to Snowflake Experiment Tracking\n",
    "    with exp.start_run():\n",
    "        exp.log_param(\"model_type\", name)\n",
    "        exp.log_param(\"n_features\", len(FEATURE_COLS))\n",
    "        exp.log_param(\"train_samples\", train_df.count())\n",
    "        exp.log_param(\"test_samples\", test_df.count())\n",
    "        \n",
    "        exp.log_metric(\"mse\", mse)\n",
    "        exp.log_metric(\"rmse\", rmse)\n",
    "        exp.log_metric(\"mae\", mae)\n",
    "        exp.log_metric(\"r2\", r2)\n",
    "        \n",
    "        # Log pipeline with Snowpark DF sample\n",
    "        exp.log_model(\n",
    "            model=pipeline, \n",
    "            model_name=f\"{name}_model\", \n",
    "            sample_input_data=train_df.select(FEATURE_COLS).limit(5)\n",
    "        )\n",
    "\n",
    "logger.info(\"\\n\" + \"=\" * 60)\n",
    "logger.info(\"TRAINING COMPLETE\")\n",
    "logger.info(\"=\" * 60)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303597ae-4a03-4d0e-9cf7-d1cd96620912",
   "metadata": {
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "## 4. Model Selection & Results\n",
    "\n",
    "Compare model performance and identify the best model for production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93e01a-8bed-4bc6-8c49-05a0424e956e",
   "metadata": {
    "language": "python",
    "name": "cell46"
   },
   "outputs": [],
   "source": [
    "# Create results comparison DataFrame\n",
    "results_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": r[\"name\"],\n",
    "        \"MSE\": r[\"mse\"],\n",
    "        \"RMSE\": r[\"rmse\"],\n",
    "        \"MAE\": r[\"mae\"],\n",
    "        \"R¬≤\": r[\"r2\"]\n",
    "    }\n",
    "    for r in results\n",
    "]).sort_values(\"RMSE\")\n",
    "\n",
    "logger.info(\"\\nüìä MODEL COMPARISON (sorted by RMSE):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identify best model (lowest RMSE)\n",
    "best_model_result = min(results, key=lambda x: x[\"rmse\"])\n",
    "best_model_name = best_model_result[\"name\"]\n",
    "best_model_pipeline = best_model_result[\"pipeline\"]\n",
    "\n",
    "logger.info(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "logger.info(f\"   RMSE: {best_model_result['rmse']:.4f}\")\n",
    "logger.info(f\"   R¬≤: {best_model_result['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13efa655-5d44-4dfb-bd22-96dd70903135",
   "metadata": {
    "language": "python",
    "name": "cell42"
   },
   "outputs": [],
   "source": [
    "## 5. Model Registry\n",
    "\n",
    "# Register the best model for production deployment\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "registry = Registry(\n",
    "    session=session, \n",
    "    database_name=CONFIG[\"database\"], \n",
    "    schema_name=\"data_science\"\n",
    ")\n",
    "\n",
    "logger.info(\"Connected to Snowflake Model Registry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f89ad9-593f-4f49-b193-852fd22de4ea",
   "metadata": {
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "# Register the best model as champion\n",
    "MODEL_NAME = \"user_activity_predictor\"\n",
    "MODEL_VERSION = \"v1.0\"\n",
    "\n",
    "model_version = registry.log_model(\n",
    "    model=best_model_pipeline,\n",
    "    model_name=MODEL_NAME,\n",
    "    version_name=MODEL_VERSION,\n",
    "    comment=f\"Best baseline model: {best_model_name} | RMSE: {best_model_result['rmse']:.4f} | R¬≤: {best_model_result['r2']:.4f}\",\n",
    "    sample_input_data=X_train.head(),\n",
    "    metrics={\n",
    "        \"rmse\": best_model_result[\"rmse\"],\n",
    "        \"mse\": best_model_result[\"mse\"],\n",
    "        \"mae\": best_model_result[\"mae\"],\n",
    "        \"r2\": best_model_result[\"r2\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "logger.info(f\"‚úÖ Model '{model_version.model_name}' version '{model_version.version_name}' registered successfully!\")\n",
    "logger.info(f\"   Algorithm: {best_model_name}\")\n",
    "logger.info(f\"   Metrics: RMSE={best_model_result['rmse']:.4f}, R¬≤={best_model_result['r2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fc0868-0467-4c37-91f7-b9407765adf5",
   "metadata": {
    "collapsed": false,
    "name": "cell43"
   },
   "source": [
    "## 6. Inference (Example)\n",
    "\n",
    "Load the registered model and make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00eb68-8ea1-4b9b-9646-eec8ba6f0a75",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": [
    "# Load model from registry for inference\n",
    "loaded_model = registry.get_model(MODEL_NAME).version(MODEL_VERSION)\n",
    "\n",
    "# Example: Make predictions on test data (using Snowpark DF)\n",
    "predictions_df = loaded_model.run(test_df.select(FEATURE_COLS))\n",
    "\n",
    "# Get prediction stats\n",
    "pred_stats = predictions_df.select(\"PREDICTION\").agg({\n",
    "    \"PREDICTION\": [\"count\", \"min\", \"max\"]\n",
    "}).collect()[0]\n",
    "\n",
    "logger.info(f\"Generated {pred_stats[0]} predictions\")\n",
    "logger.info(f\"Prediction range: {pred_stats[1]:.2f} - {pred_stats[2]:.2f}\")\n",
    "\n",
    "# Summary\n",
    "logger.info(\"\\n\" + \"=\" * 60)\n",
    "logger.info(\"PIPELINE COMPLETE! (Using Snowflake ML)\")\n",
    "logger.info(\"=\" * 60)\n",
    "logger.info(f\"‚úÖ Feature Store: 5 feature views registered\")\n",
    "logger.info(f\"‚úÖ Experiments: {len(baseline_models)} models trained and logged\")\n",
    "logger.info(f\"‚úÖ Best Model: {best_model_name} (RMSE: {best_model_result['rmse']:.4f})\")\n",
    "logger.info(f\"‚úÖ Model Registry: {MODEL_NAME} v{MODEL_VERSION} registered\")\n",
    "logger.info(f\"‚úÖ All training done IN Snowflake - no data downloaded!\")\n",
    "logger.info(\"=\" * 60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "elie.niringiyim@textnow.com",
   "authorId": "522148860138",
   "authorName": "ELIE.NIRINGIYIM@TEXTNOW.COM",
   "lastEditTime": 1764735953621,
   "notebookId": "5kj7agku7vegpv2ackxz",
   "sessionId": "6ce57023-d619-45d7-aead-01ccbd08699f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
